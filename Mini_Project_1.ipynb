{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eslam\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1 = pd.read_csv(\"D:/NU/Data Mining/Mini Project/Training_Data/twitter-2013train.txt\", sep='\\t', header=None)\n",
    "file_2 = pd.read_csv(\"D:/NU/Data Mining/Mini Project/Training_Data/twitter-2015train.txt\", sep='\\t', header=None)\n",
    "file_3 = pd.read_csv(\"D:/NU/Data Mining/Mini Project/Training_Data/twitter-2016train.txt\", sep='\\t', header=None)\n",
    "all_files = pd.concat([file_1, file_2, file_3], ignore_index=True)\n",
    "sLength = len(all_files[2])\n",
    "all_files[3] = pd.Series(np.random.randn(sLength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.array(all_files.drop([0],1)))\n",
    "data_train = data.drop([0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[2] = pow(data_train[2], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data,train_labels,test_labels = train_test_split(data_train,all_files[1], test_size=0.2,random_state=1)\n",
    "\n",
    "dlen = np.array(train_data[2]) \n",
    "tlen = np.array(test_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    vectorizer = CountVectorizer(min_df=2 ).fit(train_data[1])\n",
    "    #vectorizer2 = CountVectorizer(min_df=2 ).fit(train_data[2])\n",
    "    \n",
    "    train_data_vectorized = vectorizer.transform(train_data[1])\n",
    "    #train_data_2_vectorized = vectorizer2.transform(train_data[2])\n",
    "    test_data_vectorized = vectorizer.transform(test_data[1])\n",
    "    #test_data_2_vectorized = vectorizer2.transform(test_data[2])\n",
    "    \n",
    "    clfr = naive_bayes.MultinomialNB()\n",
    "    clfr.fit(train_data_vectorized, train_labels)\n",
    "    predicted = clfr.predict(test_data_vectorized)\n",
    "    acc = metrics.accuracy_score(test_labels,predicted)\n",
    "    print ('accuracy = '+str(acc*100)+'%')\n",
    "    print (metrics.classification_report(test_labels,predicted))\n",
    "    return train_data_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 64.38142723589904%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.57      0.41      0.48       498\n",
      "    neutral       0.67      0.62      0.65      1361\n",
      "   positive       0.64      0.75      0.69      1350\n",
      "\n",
      "avg / total       0.64      0.64      0.64      3209\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<12832x9732 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 218628 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_try():\n",
    "    vectorizer = TfidfVectorizer().fit(train_data[1])\n",
    "    train_data_vectorized = vectorizer.transform(train_data[1])\n",
    "    test_data_vectorized = vectorizer.transform(test_data[1])\n",
    "    print (len(vectorizer.get_feature_names()))\n",
    "    clfr = svm.SVC(kernel='linear', C=1)\n",
    "    clfr.fit(train_data_vectorized,train_labels)\n",
    "    predicted = clfr.predict(test_data_vectorized)\n",
    "    acc = metrics.accuracy_score(test_labels,predicted)\n",
    "    print ('accuracy = '+str(acc*100)+'%')\n",
    "    print (metrics.classification_report(test_labels,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28795\n",
      "accuracy = 67.12371455282019%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.65      0.36      0.46       498\n",
      "    neutral       0.64      0.74      0.69      1361\n",
      "   positive       0.71      0.72      0.71      1350\n",
      "\n",
      "avg / total       0.67      0.67      0.66      3209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_try()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
